#!/usr/bin/env python3

import argparse
import os

import ansible_runner
from dotenv import dotenv_values


def parse_arguments():
    """
    Parses command line arguments.

    Returns:
        Namespace: The parsed arguments.
    """
    parser = argparse.ArgumentParser(
        description="Generate an Ansible inventory file from input hostnames."
    )
    parser.add_argument(
        "--redis", nargs="+", required=True, help="List of redis hostnames, separated by space."
    )
    parser.add_argument(
        "--metadata",
        nargs="+",
        required=True,
        help="List of metadata server hostnames, separated by space.",
    )
    parser.add_argument(
        "--backends",
        nargs="+",
        required=True,
        help="List of backend server hostnames, separated by space.",
    )
    parser.add_argument(
        "--network",
        default="-ib0",
        help="Network suffix for all hostnames. Defaults to 'infiniband'.",
    )
    parser.add_argument(
        "--env-file",
        default=".env",
        help="Path to the file containing environment variables. Defaults to '.env'.",
    )

    return parser.parse_args()


def run_ansible_playbook(inventory, env_vars):
    """
    Runs the Ansible playbook with the specified in-memory inventory and environment variables.

    Args:
        inventory (dict): The in-memory inventory to use.
        env_vars (dict): Dictionary with environment variables.
    """
    # Construct the playbook path
    dataclay_home = env_vars["DATACLAY_HOME"]
    playbook_path = os.path.join(dataclay_home, "config", "deploy-playbook.yaml")

    print("Running Ansible playbook: ", playbook_path)

    # Run the ansible playbook
    runner_response = ansible_runner.run(
        private_data_dir=env_vars["DATACLAY_JOB_PATH"],
        playbook=playbook_path,
        inventory=inventory,
        envvars=env_vars,
    )

    if runner_response.status == "successful":
        print("Ansible playbook executed successfully.")
        # print("Output: ", runner_response.stdout.read())
    else:
        print(f"Ansible playbook execution failed: {runner_response.status}")
        print("Output: ", runner_response.stdout.read())
        exit(1)


if __name__ == "__main__":
    print("Starting dataClay deployment...")

    #############
    # HOSTNAMES #
    #############

    args = parse_arguments()

    # if args.network == "infiniband":
    #     suffix = "-ib0"
    # elif args.network == "ethernet":
    #     suffix = "-eth0"
    # else:
    #     suffix = args.network

    # redis_servers = [f"{server}{suffix}" for server in args.redis]
    # metadata_servers = [f"{server}{suffix}" for server in args.metadata]
    # backend_servers = [f"{server}{suffix}" for server in args.backends]

    # Suffix already included in the hostnames
    redis_servers = args.redis
    metadata_servers = args.metadata
    backend_servers = args.backends

    print("\nHostnames:")
    print("\tRedis servers: ", redis_servers)
    print("\tMetadata servers: ", metadata_servers)
    print("\tBackend servers: ", backend_servers)

    #########################
    # ENVIRONMENT VARIABLES #
    #########################

    # Load the environment variables from the file (if it exists)
    env_vars = {}
    if os.path.exists(args.env_file):
        print("Loading environment variables from ", args.env_file)
        env_vars = dotenv_values(args.env_file)
    else:
        print("Environment variables file not found: ", args.env_file)

    # Add the current environment variables to the dictionary
    env_vars.update(os.environ)

    # Add the dynamic environment variables
    env_vars["DATACLAY_METADATA_HOST"] = metadata_servers[0]
    env_vars["DATACLAY_KV_HOST"] = redis_servers[0]
    env_vars["PYTHONPATH"] = f"{os.environ.get('PYTHONPATH')}:{os.getcwd()}"

    # Create folers
    env_vars["DATACLAY_JOB_PATH"] = f"{env_vars['HOME']}/.dataclay/{env_vars['SLURM_JOB_ID']}"
    env_vars["DATACLAY_LOG_PATH"] = env_vars["DATACLAY_JOB_PATH"] + "/logs"
    env_vars["DATACLAY_STORAGE_PATH"] = env_vars["DATACLAY_JOB_PATH"] + "/storage"

    for path in [env_vars["DATACLAY_LOG_PATH"], env_vars["DATACLAY_STORAGE_PATH"]]:
        os.makedirs(path, exist_ok=True)

    print("Created job folder: ", env_vars["DATACLAY_JOB_PATH"])

    #############
    # INVENTORY #
    #############

    # Create an in-memory inventory
    inventory = {
        "redis": {
            "hosts": {server: {} for server in redis_servers},
        },
        "metadata": {
            "hosts": {server: {} for server in metadata_servers},
        },
        "backend": {
            "hosts": {server: {} for server in backend_servers},
        },
    }

    ############
    # PLAYBOOK #
    ############

    run_ansible_playbook(inventory, env_vars)
